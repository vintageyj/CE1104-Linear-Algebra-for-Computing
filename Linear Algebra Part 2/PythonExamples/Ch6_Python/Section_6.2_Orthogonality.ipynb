{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonality\n",
    "# Author: Zhang Su (Teaching Assistant)\n",
    "# Using python3, numpy\n",
    "# 2 June 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Outcome\n",
    "\n",
    "By the end of this material, you should be able to:\n",
    "\n",
    "+ Determine the orthogonality of two vectors,\n",
    "+ Calculate the project of a vector onto a (unit) vector,\n",
    "+ Verify an orthogonal and orthonormal sets,\n",
    "+ Normalize an orthogonal sets to an orthonormal sets,\n",
    "+ Carry out orthogonal decomposition in a column-wise and matrix operation manners.\n",
    "\n",
    "Note: \n",
    "1. If you occasionally double clicked a textual cell, the display would change to markdown source code. To reverse, simply click anywhere of that markdown cell,  and then click **Run** in the top manu.\n",
    "2. Sometimes the notebook may not be responding. That is caused by the failure of jupyter kernel. To repair, try clicking **Kernel** in the top manu, then clicking **Reconnect**. \n",
    "3. Section Takeaways summarizes useful tips, e.g., holes of Python to avoid, if any.\n",
    "4. Section Practice reflect the learning outcomes. You are expected to solve them based on your understanding on the lecture notes alone with the coding skills learned from this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents <a name=\"Table_of_Content\"></a>\n",
    "+ 6.2.1 [Orthogonality Definition](#Orthogonality_Definition) \n",
    "+ 6.2.2 [Orthogonal Projection](#Orthogonal_Projection) \n",
    "+ 6.2.3 [Orthogonal Sets](#Orthogonal_Sets) \n",
    "+ 6.2.4 [Orthonormal Sets](#Orthonormal_Sets) \n",
    "+ 6.2.5 [Orthogonal Decomposition](#Orthogonal_Decomposition) \n",
    "+ [Takeaways](#Takeaways)\n",
    "+ [Practice](#Practice)\n",
    "\n",
    "Let's import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonality Definition<a name=\"Orthogonality_Definition\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part of code is for Section 6.2.1.**\n",
    "\n",
    "To determine the orthogonality, one should simply calculate the dot product of two given vectors. $0$ denote that the two vectors are orthogonal.\n",
    "\n",
    "The following two vectors are not orthogonal since their dot product does not equal $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product of u and v =\n",
      " [[0.43534345]]\n"
     ]
    }
   ],
   "source": [
    "u = np.random.rand(3,1)\n",
    "v = np.random.rand(3,1)\n",
    "\n",
    "ortho_uv = np.dot(u.T,v)\n",
    "print('The dot product of u and v =\\n',ortho_uv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Projection<a name=\"Orthogonal_Projection\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part of code is for Section 6.2.2.**\n",
    "\n",
    "Given a basis vector $a$, the projection of $u$ onto $a$ is formulated as:\n",
    "\n",
    "$$\n",
    "proj_au = w_1 = \\frac{u\\cdot a}{\\|a\\|^2}a, \\tag{1}\n",
    "$$\n",
    "\n",
    "or, if $a$ is already a unit vector:\n",
    "\n",
    "$$\n",
    "proj_au = w_1 = (u\\cdot a)a. \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When a is not a unit vector, the projected component is\n",
      " [[ 2.85714286 -0.71428571  1.42857143]]\n",
      "\n",
      "When a is a unit vector, the projected component is\n",
      " [[ 2.85714286 -0.71428571  1.42857143]]\n",
      "\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "# Initiate u and a, don't miss the dtype!\n",
    "u = np.array([[2, -1, 3]], dtype=float)\n",
    "a = np.array([[4, -1, 2]], dtype=float)\n",
    "\n",
    "# Normalize a\n",
    "a_unit = a / la.norm(a)\n",
    "\n",
    "# Eq. 1\n",
    "w1 = u.dot(a.T) / (la.norm(a) ** 2) * a\n",
    "\n",
    "# Eq. 2\n",
    "w1_2 = u.dot(a_unit.T) * a_unit\n",
    "\n",
    "print(\"When a is not a unit vector, the projected component is\\n\", w1)\n",
    "print(\"\\nWhen a is a unit vector, the projected component is\\n\", w1_2)\n",
    "\n",
    "# Verify the equivalence\n",
    "print(\"\\nAre they equal?\", np.allclose(w1, w1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the $w_1$, the vector component of $u$ along $a$ is obtained, we can further obtain the vector component of $u$ orthogonal to $a$ by:\n",
    "\n",
    "$$\n",
    "w_2 = u - w_1 \\tag{3}\n",
    "$$\n",
    "\n",
    "$w_2$ is the *residual* when $a$ is used to approximate $u$. It is orthogonal to $a$ so that the Pythagoras theorem holds as\n",
    "\n",
    "$$\n",
    "\\|u\\|^2 = \\|w_1\\|^2 + \\|w_2\\|^2. \\tag{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The residual of the projection is: \n",
      " [[-0.85714286 -0.28571429  1.57142857]]\n"
     ]
    }
   ],
   "source": [
    "# Eq. 3\n",
    "w2 = u - w1\n",
    "\n",
    "print(\"The residual of the projection is: \\n\", w2)\n",
    "\n",
    "# Eq. 4 is left for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Sets<a name=\"Orthogonal_Sets\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part of code is for Section 6.2.3.**\n",
    "\n",
    "An orthogonal set $\\{u_1, u_2, \\ldots, u_n\\}$ is a collection of vectors satisfying $u_i\\cdot u_j=0$, $i\\neq j$.\n",
    "\n",
    "We have two ways to verify the orthogonality of a set using Python, i.e., in a column-wise manner or using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initialized U values =\n",
      " [[ 3.  -1.  -0.5]\n",
      " [ 1.   2.  -2. ]\n",
      " [ 1.   1.   3.5]]\n"
     ]
    }
   ],
   "source": [
    "U = np.array([[3,-1,-1/2],\n",
    "             [1,2,-2],\n",
    "             [1,1,7/2]]) # Make sure that there are double square brackets.\n",
    "\n",
    "print('The initialized U values =\\n',U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column-wise \n",
    "\n",
    "Following the orthogonality definition, we can separately calculate the dot product of two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product of u1 and u2 is 0.0\n",
      "The dot product of u1 and u3 is 0.0\n",
      "The dot product of u2 and u3 is 0.0\n"
     ]
    }
   ],
   "source": [
    "col1_col2 = U[:, 0].T.dot(U[:, 1])\n",
    "col1_col3 = U[:, 0].T.dot(U[:, 2])\n",
    "col2_col3 = U[:, 1].T.dot(U[:, 2])\n",
    "\n",
    "print(\"The dot product of u1 and u2 is\", col1_col2)\n",
    "print(\"The dot product of u1 and u3 is\", col1_col3)\n",
    "print(\"The dot product of u2 and u3 is\", col2_col3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Multiplication\n",
    "\n",
    "Or using matrix operation in one go.\n",
    "\n",
    "We will use `np.dot()` method. Note that we are to check the orthogonality of columns, we should use `np.dot(S.T, S)` instead of `np.dot(S, S.T)`, because the latter is checking the row orthogonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonality check for columns =\n",
      " [[11.   0.   0. ]\n",
      " [ 0.   6.   0. ]\n",
      " [ 0.   0.  16.5]]\n",
      "Orthogonality check for rows =\n",
      " [[10.25  2.    0.25]\n",
      " [ 2.    9.   -4.  ]\n",
      " [ 0.25 -4.   14.25]]\n"
     ]
    }
   ],
   "source": [
    "orthogonality_check = np.dot(U.T, U)\n",
    "orthogonality_check_2 = np.dot(U, U.T)\n",
    "\n",
    "print('Orthogonality check for columns =\\n',orthogonality_check)\n",
    "print('Orthogonality check for rows =\\n',orthogonality_check_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `orthogonality_check`, we actually computed\n",
    "$$\n",
    "U^TU=\\begin{pmatrix}\n",
    "\\|u_1\\|^2 & u_1^Tu_2 & u_1^Tu_3 \\\\\n",
    "u_2^Tu_1 & \\|u_2\\|^2 & u_2^Tu_3 \\\\\n",
    "u_3^Tu_1 & u_3^Tu_2 & \\|u_3\\|^2\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "we see that outputted `orthogonality_check` is a diagonal matrix. Since the entry in the $i-$th row and $j-$th column represents the orthogonality check for the $i-$th and $j-$th columns of $U$, the result will be a symmetric matrix. And if the non-diagonal entries are zero, then the corresponding columns of $U$ are orthogonal, forming an orthogonal set.\n",
    "\n",
    "If we consider a vector to be the minimal element, then $U^TU$ carried out computations of $\\mathcal{O}(n^2)$ complexity, where $n$ denote the number of columns. (For the big O notation, please see [this link](https://en.wikipedia.org/wiki/Big_O_notation).) Indeed, $U$ has 3 columns, and we actually did 6 dot product and 3 norm computations, totally 9 computations, equaling to the number of entries in $U^TU$ .\n",
    "\n",
    "`orthogonality_check_2`, on the other hand,  shows that the rows of `S` are not an orthogonal set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthonormal sets<a name=\"Orthonormal_Sets\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part of code is for Section 6.2.4.**\n",
    "\n",
    "To make `U` orthonormal, we divide each column of `S` by its length, respectively. We can even use only one line of code to achieve this \"pythonically\" ([List Comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)).\n",
    "\n",
    "It is worth noting that the result may contain some extremely small values like `5.55111512e-17`, which can be safely considered as `0`. To verify, we can simply use `np.allclose()` method to see if the resulted matrices approximate an identity matrix of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthonormal S =\n",
      " [[ 0.90453403 -0.40824829 -0.12309149]\n",
      " [ 0.30151134  0.81649658 -0.49236596]\n",
      " [ 0.30151134  0.40824829  0.86164044]]\n",
      "Orthonormal S_2 =\n",
      " [[ 0.90453403 -0.40824829 -0.12309149]\n",
      " [ 0.30151134  0.81649658 -0.49236596]\n",
      " [ 0.30151134  0.40824829  0.86164044]]\n",
      "\n",
      "\n",
      "Orthonormality check for S =\n",
      " [[1.00000000e+00 7.68155897e-19 3.00799601e-17]\n",
      " [7.68155897e-19 1.00000000e+00 2.69677331e-17]\n",
      " [3.00799601e-17 2.69677331e-17 1.00000000e+00]]\n",
      "Orthonormality check for S_2 =\n",
      " [[1.00000000e+00 7.68155897e-19 3.00799601e-17]\n",
      " [7.68155897e-19 1.00000000e+00 2.69677331e-17]\n",
      " [3.00799601e-17 2.69677331e-17 1.00000000e+00]]\n",
      "\n",
      "\n",
      "Orthonormality holds? True\n",
      "Orthonormality holds? True\n"
     ]
    }
   ],
   "source": [
    "# Column-wise normalization\n",
    "orthonormal_U = []\n",
    "for column in U.T:\n",
    "    unit_column = column / la.norm(column)\n",
    "    orthonormal_U.append(unit_column)\n",
    "orthonormal_U = np.column_stack(orthonormal_U)\n",
    "\n",
    "# Column-wise normalization with Python List Comprehensions.\n",
    "orthonormal_U_2 = np.column_stack([column/la.norm(column) for column in U.T])\n",
    "\n",
    "\n",
    "print('Orthonormal S =\\n',orthonormal_U)\n",
    "print('Orthonormal S_2 =\\n',orthonormal_U_2)\n",
    "print('\\n')\n",
    "orthonormal_check = np.dot(orthonormal_U.T, orthonormal_U)\n",
    "orthonormal_check_2 = np.dot(orthonormal_U_2.T, orthonormal_U_2)\n",
    "\n",
    "print('Orthonormality check for S =\\n',orthonormal_check)\n",
    "print('Orthonormality check for S_2 =\\n',orthonormal_check_2)\n",
    "print('\\n')\n",
    "\n",
    "# Verify if the 3-by-3 UTU approximates a 3-by-3 identity matrix\n",
    "print('Orthonormality holds?', np.allclose(orthonormal_check, np.eye(3)))\n",
    "print('Orthonormality holds?', np.allclose(orthonormal_check_2, np.eye(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Decomposition<a name=\"Orthogonal_Decomposition\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part of code is for Section 6.2.5.**\n",
    "\n",
    "Given a space $W$ spanned by basis $\\{u_1, u_2, \\ldots, u_p\\}$ and an arbitrary vector $y$, the prthogonal projection of $y$ onto $W$ is formulated as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{y\\cdot u_1}{u_1\\cdot u_1}u_1 + \\cdots + \\frac{y\\cdot u_p}{u_p\\cdot u_p}u_p, \\tag{5}\n",
    "$$\n",
    "\n",
    "if the basis is **not** an orthonormal basis, or\n",
    "\n",
    "$$\n",
    "\\hat{y} = (u_1\\cdot u_1)u_1 + \\cdots + (u_p\\cdot u_p)u_p, \\tag{6}\n",
    "$$\n",
    "\n",
    "if the basis **is** an orthonormal basis.\n",
    "\n",
    "After the projection $\\hat{y}$ is obtained, the residual $z$ which is orthogonal to $W$ can be obtained by:\n",
    "\n",
    "$$\n",
    "z = y - \\hat{y} \\tag{7}\n",
    "$$\n",
    "\n",
    "So far we can say that $\\hat{y}$ is the closest point in $W$ to $y$, following the Best Approximation Theorem:\n",
    "\n",
    "$$\n",
    "Error = \\|y-\\hat{y}\\|<\\|y-u\\|, \\tag{8}\n",
    "$$\n",
    "\n",
    "with an error of $\\|z\\|$. Let's see the example below.\n",
    "\n",
    "\n",
    "\n",
    "![title](img/projection_problem.png)\n",
    "\n",
    "We use two equivalent ways to solve it. One is in a column-wise manner, and another one uses the projection matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "u1, u2, y = np.array([[-7,1,4]]).T, np.array([[-1,1,-2]]).T, np.array([[-9,1,6]]).T\n",
    "\n",
    "# Pay attention to how to stack the column vectors u1 and u2.\n",
    "W = np.column_stack((u1, u2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column-wise\n",
    "\n",
    "The column-wise method first calculate the projections of $u_1$ and $u_2$ onto $y$, and then calculate $proj_W y$., i.e.:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p_1 &= \\frac{u_1\\cdot y}{u_1\\cdot u_1} \\tag{9}\\\\\n",
    "p_2 &= \\frac{u_2\\cdot y}{u_2\\cdot u_2} \\tag{10}\\\\\n",
    "\\hat{y} &= u1\\cdot p_1 + u2\\cdot p_2  \\tag{11}\\\\\n",
    "error &= \\|y -  \\hat{y} \\tag{12}\\|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $p_1$ and $p_2$ denote the projection of $y$ onto $u_1$ and $u_2$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonality check for U =\n",
      " [[66  0]\n",
      " [ 0  6]]\n",
      "Orthogonality check for u1 and u2 =\n",
      " [[0]]\n",
      "The estimated y =\n",
      " [[-9.]\n",
      " [ 1.]\n",
      " [ 6.]]\n",
      "The error  =\n",
      " 1.7763568394002505e-15\n"
     ]
    }
   ],
   "source": [
    "orthogonality_check_of_W = np.dot(W.T, W)\n",
    "orthogonality_check_of_u1_u2 = np.dot(u1.T, u2)\n",
    "\n",
    "print('Orthogonality check for U =\\n',orthogonality_check_of_W)\n",
    "print('Orthogonality check for u1 and u2 =\\n',orthogonality_check_of_u1_u2)\n",
    "\n",
    "# Equation 9 and 10\n",
    "p1 = np.dot(y.T, u1) / np.dot(u1.T,  u1) # Be careful! The / operator requires equal dimension.\n",
    "p2 = np.dot(y.T, u2) / np.dot(u2.T,  u2)\n",
    "\n",
    "# Equation 11\n",
    "y_hat = u1 * p1 + u2 * p2\n",
    "\n",
    "\n",
    "error = la.norm(y - y_hat)\n",
    "\n",
    "print('The estimated y =\\n',y_hat)\n",
    "print('The error  =\\n',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projection Matrix\n",
    "\n",
    "The projection matrix method first normalize $u_1$ and $u_2$ to form a orthonormal set, and then calculate the projection matrix as $UU^T$. I.e.,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "u_1' &= \\frac{u_1}{||u_1||} \\tag{13}\\\\\n",
    "u_2' &= \\frac{u_2}{||u_2||} \\tag{14}\\\\\n",
    "U &= [u_1' u_2'] \\tag{15} \\\\\n",
    "\\hat{y} &= UU^Ty \\tag{16} \\\\\n",
    "error &= \\|y - \\hat{y}\\| \\tag{17}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90909091 -0.27272727 -0.09090909]\n",
      " [-0.27272727  0.18181818 -0.27272727]\n",
      " [-0.09090909 -0.27272727  0.90909091]]\n",
      "The orthonormal matrix W' =\n",
      " [[-0.86164044 -0.40824829]\n",
      " [ 0.12309149  0.40824829]\n",
      " [ 0.49236596 -0.81649658]]\n",
      "\n",
      "Check the orthonormality. True\n",
      "\n",
      "The estimated y =\n",
      " [[-9.]\n",
      " [ 1.]\n",
      " [ 6.]]\n",
      "\n",
      "The error  =\n",
      " 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# Equation 12 and 13, using the List Comprehensions of Python\n",
    "orthonormal_W = np.column_stack([column/la.norm(column) for column in W.T])\n",
    "\n",
    "## Equation 12 and 13, alternatively.\n",
    "# orthonormal_W = []\n",
    "# for column in W.T:\n",
    "#     unit_column = column / la.norm(column)\n",
    "#     orthonormal_W.append(unit_column)\n",
    "# orthonormal_W = np.column_stack(orthonormal_W)\n",
    "\n",
    "# Equation 15\n",
    "projection_matrix = np.dot(orthonormal_W, orthonormal_W.T)\n",
    "print(projection_matrix)\n",
    "y_hat = np.dot(projection_matrix, y)\n",
    "# Equation 16\n",
    "error = la.norm(y - y_hat)\n",
    "\n",
    "print('The orthonormal matrix W\\' =\\n',orthonormal_W)\n",
    "print('\\nCheck the orthonormality.', np.allclose(orthonormal_W.T.dot(orthonormal_W), np.eye(orthonormal_W.shape[1])))\n",
    "\n",
    "print('\\nThe estimated y =\\n',y_hat)\n",
    "print('\\nThe error  =\\n',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways<a name=\"Takeaways\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "1. Pay attention to how to stack column vectors to a matrix, i.e., using `np.column_stack((u1, u2, u3))` or `np.c_[u1, u2, u3]`.\n",
    "2. [List comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) are sublimely elegent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice<a name=\"Practice\"></a>\n",
    "[Return to Table of Content](#Table_of_Content)\n",
    "\n",
    "**This part can get you ready for the lab!**\n",
    "\n",
    "Given $A=\\begin{pmatrix}\n",
    "6 & -6 & -6 \\\\\n",
    "6 & -6 & 6 \\\\\n",
    "6 & 6  & -6 \\\\\n",
    "6 & 6  & 6 \n",
    "\\end{pmatrix}$\n",
    "\n",
    "1. Generate a new matrix $U$ by normalizing each column of $A$ and verify the orthonormality.\n",
    "2. Given a vector $y=(1,2,3,4)$, carry out the orthogonal decomposition of $y$ onto $Col\\,\\,U$ in two ways, i.e., following Eq. 9, 10, 11, 12 AND Eq. 13, 14, 15, 16, 17, respectively.\n",
    "3. What's the error of the projection in 2?\n",
    "4. Examine the Pythagoras Theorem between $z$, $u_i$, and $y$ following Eq. 4.\n",
    "5. Find the closest point to $x=(1,0,0,2)$ in $Col\\,\\,U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
